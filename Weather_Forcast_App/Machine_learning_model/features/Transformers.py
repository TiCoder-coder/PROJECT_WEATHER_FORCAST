# ----------------------------- TRANSFORMERS - MODULE BIáº¾N Äá»”I Dá»® LIá»†U -----------------------------------------------------------
"""
Transformers.py - CÃ¡c transformer dáº¡ng module dÃ¹ng láº¡i cho machine learning pipeline

Má»¥c Ä‘Ã­ch:
    - StandardScaler/MinMaxScaler/RobustScaler (cÃ³ thá»ƒ fit & transform riÃªng)
    - Encoding cho categorical features (Label/OneHot/Target encoding)
    - Xá»­ lÃ½ missing values nÃ¢ng cao (KNN imputer, iterative imputer)
    - Pipeline transform thá»‘ng nháº¥t cho train & predict
    - Äáº£m báº£o: "train vÃ  predict dÃ¹ng Ä‘Ãºng cÃ¹ng 1 kiá»ƒu transform"

Chá»©c nÄƒng chÃ­nh:
    - WeatherScaler: Wrapper cho cÃ¡c loáº¡i scaler
    - CategoricalEncoder: Encoding categorical features
    - MissingValueHandler: Xá»­ lÃ½ missing values
    - WeatherTransformPipeline: Pipeline tá»•ng há»£p

CÃ¡ch sá»­ dá»¥ng:
    from Weather_Forcast_App.Machine_learning_model.features.Transformers import WeatherTransformPipeline
    
    # Training
    pipeline = WeatherTransformPipeline()
    X_train_transformed = pipeline.fit_transform(X_train)
    pipeline.save('pipeline.pkl')
    
    # Prediction
    pipeline = WeatherTransformPipeline.load('pipeline.pkl')
    X_pred_transformed = pipeline.transform(X_pred)
"""

import pandas as pd
import numpy as np
import joblib
import json
import logging
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any, Union
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
import warnings

warnings.filterwarnings('ignore')

# Sklearn imports
from sklearn.preprocessing import (
    StandardScaler, MinMaxScaler, RobustScaler,
    LabelEncoder, OneHotEncoder, OrdinalEncoder
)
from sklearn.impute import SimpleImputer, KNNImputer
from sklearn.base import BaseEstimator, TransformerMixin

# Setup logging
logger = logging.getLogger(__name__)


# ============================= CONSTANTS =============================

SCALER_TYPES = {
    'standard': StandardScaler,
    'minmax': MinMaxScaler,
    'robust': RobustScaler
}

IMPUTER_STRATEGIES = ['mean', 'median', 'most_frequent', 'constant', 'knn']

ENCODER_TYPES = ['label', 'onehot', 'ordinal', 'target']


# ============================= BASE TRANSFORMER =============================

class BaseWeatherTransformer(ABC, BaseEstimator, TransformerMixin):
    """
    Base class cho táº¥t cáº£ Weather Transformers.
    
    Káº¿ thá»«a tá»« sklearn BaseEstimator vÃ  TransformerMixin Ä‘á»ƒ:
    - TÆ°Æ¡ng thÃ­ch vá»›i sklearn Pipeline
    - CÃ³ sáºµn fit_transform() method
    - CÃ³ thá»ƒ clone vÃ  serialize
    """
    
    def __init__(self, name: str = "BaseTransformer"):
        self.name = name
        self.is_fitted = False
        self._fitted_columns: List[str] = []
    
    @abstractmethod
    def fit(self, X: pd.DataFrame, y: Optional[pd.Series] = None):
        """Fit transformer vá»›i dá»¯ liá»‡u training."""
        pass
    
    @abstractmethod
    def transform(self, X: pd.DataFrame) -> pd.DataFrame:
        """Transform dá»¯ liá»‡u."""
        pass
    
    def fit_transform(self, X: pd.DataFrame, y: Optional[pd.Series] = None) -> pd.DataFrame:
        """Fit vÃ  transform trong má»™t bÆ°á»›c."""
        self.fit(X, y)
        return self.transform(X)
    
    def get_params(self, deep: bool = True) -> Dict[str, Any]:
        """Láº¥y parameters cá»§a transformer."""
        return {'name': self.name}
    
    def set_params(self, **params) -> 'BaseWeatherTransformer':
        """Set parameters cho transformer."""
        for key, value in params.items():
            setattr(self, key, value)
        return self


# ============================= WEATHER SCALER =============================

class WeatherScaler(BaseWeatherTransformer):
    """
    Scaler cho numerical features trong dá»¯ liá»‡u thá»i tiáº¿t.
    
    Wrapper cho StandardScaler/MinMaxScaler/RobustScaler vá»›i:
    - Tá»± Ä‘á»™ng detect numerical columns
    - LÆ°u láº¡i column names Ä‘á»ƒ Ä‘áº£m báº£o consistency
    - Support fit/transform riÃªng biá»‡t
    
    Attributes:
        scaler_type: Loáº¡i scaler ('standard', 'minmax', 'robust')
        scaler: Sklearn scaler instance
        columns: Danh sÃ¡ch columns Ä‘Æ°á»£c scale
    """
    
    def __init__(
        self,
        scaler_type: str = 'standard',
        columns: Optional[List[str]] = None,
        **scaler_kwargs
    ):
        """
        Khá»Ÿi táº¡o WeatherScaler.
        
        Args:
            scaler_type: Loáº¡i scaler ('standard', 'minmax', 'robust')
            columns: Danh sÃ¡ch columns cáº§n scale (None = auto detect)
            **scaler_kwargs: Kwargs truyá»n vÃ o scaler
        """
        super().__init__(name="WeatherScaler")
        
        if scaler_type not in SCALER_TYPES:
            raise ValueError(f"Unsupported scaler type: {scaler_type}. "
                           f"Choose from: {list(SCALER_TYPES.keys())}")
        
        self.scaler_type = scaler_type
        self.scaler = SCALER_TYPES[scaler_type](**scaler_kwargs)
        self.columns = columns
        self._scale_columns: List[str] = []
    
    def fit(self, X: pd.DataFrame, y: Optional[pd.Series] = None) -> 'WeatherScaler':
        """
        Fit scaler vá»›i dá»¯ liá»‡u training.
        
        Args:
            X: DataFrame training data
            y: Target (khÃ´ng sá»­ dá»¥ng, Ä‘á»ƒ tÆ°Æ¡ng thÃ­ch vá»›i sklearn)
        
        Returns:
            self
        """
        # XÃ¡c Ä‘á»‹nh columns cáº§n scale
        if self.columns is not None:
            self._scale_columns = [c for c in self.columns if c in X.columns]
        else:
            # Auto detect numerical columns
            self._scale_columns = X.select_dtypes(include=[np.number]).columns.tolist()
        
        if len(self._scale_columns) == 0:
            logger.warning("KhÃ´ng cÃ³ numerical columns Ä‘á»ƒ scale!")
            self.is_fitted = True
            return self
        
        # Fit scaler
        self.scaler.fit(X[self._scale_columns])
        
        self.is_fitted = True
        self._fitted_columns = X.columns.tolist()
        
        logger.info(f"âœ… WeatherScaler ({self.scaler_type}) Ä‘Ã£ fit {len(self._scale_columns)} columns")
        return self
    
    def transform(self, X: pd.DataFrame) -> pd.DataFrame:
        """
        Transform dá»¯ liá»‡u vá»›i scaler Ä‘Ã£ fit.
        
        Args:
            X: DataFrame cáº§n transform
        
        Returns:
            DataFrame Ä‘Ã£ Ä‘Æ°á»£c scale
        """
        if not self.is_fitted:
            raise ValueError("WeatherScaler chÆ°a Ä‘Æ°á»£c fit! Gá»i fit() trÆ°á»›c.")
        
        X_result = X.copy()
        
        if len(self._scale_columns) == 0:
            return X_result
        
        # Chá»‰ scale cÃ¡c columns cÃ³ trong fitted columns
        cols_to_scale = [c for c in self._scale_columns if c in X_result.columns]
        
        if len(cols_to_scale) > 0:
            X_result[cols_to_scale] = self.scaler.transform(X_result[cols_to_scale])
        
        return X_result
    
    def inverse_transform(self, X: pd.DataFrame) -> pd.DataFrame:
        """
        Inverse transform Ä‘á»ƒ láº¥y láº¡i giÃ¡ trá»‹ gá»‘c.
        
        Args:
            X: DataFrame Ä‘Ã£ scale
        
        Returns:
            DataFrame vá»›i giÃ¡ trá»‹ gá»‘c
        """
        if not self.is_fitted:
            raise ValueError("WeatherScaler chÆ°a Ä‘Æ°á»£c fit!")
        
        X_result = X.copy()
        
        if len(self._scale_columns) == 0:
            return X_result
        
        cols_to_inverse = [c for c in self._scale_columns if c in X_result.columns]
        
        if len(cols_to_inverse) > 0:
            X_result[cols_to_inverse] = self.scaler.inverse_transform(X_result[cols_to_inverse])
        
        return X_result
    
    def get_params(self, deep: bool = True) -> Dict[str, Any]:
        """Láº¥y parameters."""
        params = super().get_params(deep)
        params.update({
            'scaler_type': self.scaler_type,
            'columns': self.columns
        })
        return params


# ============================= CATEGORICAL ENCODER =============================

class CategoricalEncoder(BaseWeatherTransformer):
    """
    Encoder cho categorical features.
    
    Há»— trá»£:
    - Label Encoding: Chuyá»ƒn categories thÃ nh sá»‘ (0, 1, 2, ...)
    - One-Hot Encoding: Táº¡o dummy columns
    - Ordinal Encoding: Encoding cÃ³ thá»© tá»±
    - Target Encoding: Encode dá»±a trÃªn mean cá»§a target
    
    Attributes:
        encoding_type: Loáº¡i encoding
        columns: Danh sÃ¡ch columns cáº§n encode
        encoders: Dict chá»©a encoder cho má»—i column
    """
    
    def __init__(
        self,
        encoding_type: str = 'label',
        columns: Optional[List[str]] = None,
        handle_unknown: str = 'ignore'
    ):
        """
        Khá»Ÿi táº¡o CategoricalEncoder.
        
        Args:
            encoding_type: Loáº¡i encoding ('label', 'onehot', 'ordinal')
            columns: Danh sÃ¡ch columns cáº§n encode (None = auto detect)
            handle_unknown: CÃ¡ch xá»­ lÃ½ categories má»›i ('ignore', 'error')
        """
        super().__init__(name="CategoricalEncoder")
        
        if encoding_type not in ENCODER_TYPES:
            raise ValueError(f"Unsupported encoding type: {encoding_type}. "
                           f"Choose from: {ENCODER_TYPES}")
        
        self.encoding_type = encoding_type
        self.columns = columns
        self.handle_unknown = handle_unknown
        self.encoders: Dict[str, Any] = {}
        self._encode_columns: List[str] = []
        self._onehot_columns: List[str] = []  # Columns sau one-hot encoding
    
    def fit(self, X: pd.DataFrame, y: Optional[pd.Series] = None) -> 'CategoricalEncoder':
        """
        Fit encoder vá»›i dá»¯ liá»‡u training.
        
        Args:
            X: DataFrame training data
            y: Target (sá»­ dá»¥ng cho target encoding)
        
        Returns:
            self
        """
        # XÃ¡c Ä‘á»‹nh columns cáº§n encode
        if self.columns is not None:
            self._encode_columns = [c for c in self.columns if c in X.columns]
        else:
            # Auto detect categorical columns
            self._encode_columns = X.select_dtypes(include=['object', 'category']).columns.tolist()
        
        if len(self._encode_columns) == 0:
            logger.info("KhÃ´ng cÃ³ categorical columns Ä‘á»ƒ encode")
            self.is_fitted = True
            return self
        
        # Fit encoders
        for col in self._encode_columns:
            if self.encoding_type == 'label':
                encoder = LabelEncoder()
                encoder.fit(X[col].astype(str).fillna('__MISSING__'))
                self.encoders[col] = encoder
                
            elif self.encoding_type == 'ordinal':
                encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)
                encoder.fit(X[[col]].astype(str).fillna('__MISSING__'))
                self.encoders[col] = encoder
                
            elif self.encoding_type == 'onehot':
                # LÆ°u unique values Ä‘á»ƒ táº¡o dummy columns nháº¥t quÃ¡n
                unique_values = X[col].astype(str).fillna('__MISSING__').unique()
                self.encoders[col] = list(unique_values)
                
            elif self.encoding_type == 'target' and y is not None:
                # Target encoding: encode báº±ng mean cá»§a target
                target_means = X.groupby(col)[y.name].mean() if y.name else {}
                global_mean = y.mean()
                self.encoders[col] = {'means': target_means.to_dict(), 'global_mean': global_mean}
        
        self.is_fitted = True
        self._fitted_columns = X.columns.tolist()
        
        logger.info(f"âœ… CategoricalEncoder ({self.encoding_type}) Ä‘Ã£ fit {len(self._encode_columns)} columns")
        return self
    
    def transform(self, X: pd.DataFrame) -> pd.DataFrame:
        """
        Transform dá»¯ liá»‡u vá»›i encoder Ä‘Ã£ fit.
        
        Args:
            X: DataFrame cáº§n transform
        
        Returns:
            DataFrame Ä‘Ã£ Ä‘Æ°á»£c encode
        """
        if not self.is_fitted:
            raise ValueError("CategoricalEncoder chÆ°a Ä‘Æ°á»£c fit! Gá»i fit() trÆ°á»›c.")
        
        X_result = X.copy()
        
        if len(self._encode_columns) == 0:
            return X_result
        
        for col in self._encode_columns:
            if col not in X_result.columns:
                continue
            
            if self.encoding_type == 'label':
                encoder = self.encoders.get(col)
                if encoder:
                    # Xá»­ lÃ½ unknown categories
                    values = X_result[col].astype(str).fillna('__MISSING__')
                    known_classes = set(encoder.classes_)
                    values = values.apply(lambda x: x if x in known_classes else '__UNKNOWN__')
                    
                    # ThÃªm __UNKNOWN__ vÃ o classes náº¿u chÆ°a cÃ³
                    if '__UNKNOWN__' not in known_classes:
                        encoder.classes_ = np.append(encoder.classes_, '__UNKNOWN__')
                    
                    X_result[col] = encoder.transform(values)
            
            elif self.encoding_type == 'ordinal':
                encoder = self.encoders.get(col)
                if encoder:
                    X_result[col] = encoder.transform(X_result[[col]].astype(str).fillna('__MISSING__')).flatten()
            
            elif self.encoding_type == 'onehot':
                unique_values = self.encoders.get(col, [])
                for val in unique_values:
                    col_name = f"{col}_{val}"
                    X_result[col_name] = (X_result[col].astype(str).fillna('__MISSING__') == val).astype(int)
                # Drop original column
                X_result = X_result.drop(columns=[col])
            
            elif self.encoding_type == 'target':
                encoding_info = self.encoders.get(col, {})
                means = encoding_info.get('means', {})
                global_mean = encoding_info.get('global_mean', 0)
                X_result[col] = X_result[col].map(means).fillna(global_mean)
        
        return X_result
    
    def get_params(self, deep: bool = True) -> Dict[str, Any]:
        """Láº¥y parameters."""
        params = super().get_params(deep)
        params.update({
            'encoding_type': self.encoding_type,
            'columns': self.columns,
            'handle_unknown': self.handle_unknown
        })
        return params


# ============================= MISSING VALUE HANDLER =============================

class MissingValueHandler(BaseWeatherTransformer):
    """
    Handler xá»­ lÃ½ missing values nÃ¢ng cao.
    
    Há»— trá»£:
    - SimpleImputer: mean, median, most_frequent, constant
    - KNNImputer: Sá»­ dá»¥ng K-nearest neighbors
    - Forward/Backward fill: Cho time series
    - Custom strategy cho tá»«ng column
    
    Attributes:
        strategy: Chiáº¿n lÆ°á»£c impute máº·c Ä‘á»‹nh
        column_strategies: Dict chiáº¿n lÆ°á»£c riÃªng cho tá»«ng column
        imputers: Dict chá»©a imputer cho má»—i nhÃ³m columns
    """
    
    def __init__(
        self,
        strategy: str = 'median',
        fill_value: Optional[Any] = None,
        column_strategies: Optional[Dict[str, str]] = None,
        n_neighbors: int = 5
    ):
        """
        Khá»Ÿi táº¡o MissingValueHandler.
        
        Args:
            strategy: Chiáº¿n lÆ°á»£c máº·c Ä‘á»‹nh ('mean', 'median', 'most_frequent', 'constant', 'knn', 'ffill', 'bfill')
            fill_value: GiÃ¡ trá»‹ fill náº¿u strategy='constant'
            column_strategies: Dict chiáº¿n lÆ°á»£c riÃªng cho tá»«ng column
            n_neighbors: Sá»‘ neighbors cho KNN imputer
        """
        super().__init__(name="MissingValueHandler")
        
        self.strategy = strategy
        self.fill_value = fill_value
        self.column_strategies = column_strategies or {}
        self.n_neighbors = n_neighbors
        self.imputers: Dict[str, Any] = {}
        self._numeric_columns: List[str] = []
        self._categorical_columns: List[str] = []
    
    def fit(self, X: pd.DataFrame, y: Optional[pd.Series] = None) -> 'MissingValueHandler':
        """
        Fit imputers vá»›i dá»¯ liá»‡u training.
        
        Args:
            X: DataFrame training data
            y: Target (khÃ´ng sá»­ dá»¥ng)
        
        Returns:
            self
        """
        # PhÃ¢n loáº¡i columns
        self._numeric_columns = X.select_dtypes(include=[np.number]).columns.tolist()
        self._categorical_columns = X.select_dtypes(include=['object', 'category']).columns.tolist()
        
        # LÆ°u fill values cho tá»«ng column (Ä‘Æ¡n giáº£n vÃ  robust hÆ¡n sklearn imputer)
        self._column_fill_values = {}
        
        # Cho numerical columns
        for col in self._numeric_columns:
            if self.strategy == 'median':
                self._column_fill_values[col] = X[col].median()
            elif self.strategy == 'mean':
                self._column_fill_values[col] = X[col].mean()
            elif self.strategy == 'most_frequent':
                mode = X[col].mode()
                self._column_fill_values[col] = mode[0] if len(mode) > 0 else 0
            elif self.strategy == 'constant':
                self._column_fill_values[col] = self.fill_value if self.fill_value is not None else 0
            else:
                self._column_fill_values[col] = X[col].median()
        
        # Cho categorical columns
        self._categorical_fill_values = {}
        for col in self._categorical_columns:
            mode = X[col].mode()
            self._categorical_fill_values[col] = mode[0] if len(mode) > 0 else '__MISSING__'
        
        # Váº«n fit KNN imputer náº¿u cáº§n (cho trÆ°á»ng há»£p Ä‘áº·c biá»‡t)
        if self.strategy == 'knn' and len(self._numeric_columns) > 0:
            try:
                imputer = KNNImputer(n_neighbors=self.n_neighbors)
                imputer.fit(X[self._numeric_columns])
                self.imputers['numeric'] = imputer
            except Exception:
                pass  # Fallback to simple fill
        
        self.is_fitted = True
        self._fitted_columns = X.columns.tolist()
        
        logger.info(f"âœ… MissingValueHandler ({self.strategy}) Ä‘Ã£ fit "
                   f"{len(self._numeric_columns)} numeric, {len(self._categorical_columns)} categorical columns")
        return self
    
    def transform(self, X: pd.DataFrame) -> pd.DataFrame:
        """
        Transform dá»¯ liá»‡u - fill missing values.
        
        Args:
            X: DataFrame cáº§n transform
        
        Returns:
            DataFrame Ä‘Ã£ Ä‘Æ°á»£c fill missing values
        """
        if not self.is_fitted:
            raise ValueError("MissingValueHandler chÆ°a Ä‘Æ°á»£c fit! Gá»i fit() trÆ°á»›c.")
        
        X_result = X.copy()
        
        # Handle numerical columns - sá»­ dá»¥ng giÃ¡ trá»‹ Ä‘Ã£ lÆ°u
        for col in self._numeric_columns:
            if col in X_result.columns and col in self._column_fill_values:
                fill_val = self._column_fill_values[col]
                # Handle NaN fill value
                if pd.isna(fill_val):
                    fill_val = 0
                X_result[col] = X_result[col].fillna(fill_val)
        
        # Handle categorical columns
        for col in self._categorical_columns:
            if col in X_result.columns and hasattr(self, '_categorical_fill_values'):
                fill_val = self._categorical_fill_values.get(col, '__MISSING__')
                X_result[col] = X_result[col].fillna(fill_val)
        
        # Handle column-specific strategies
        for col, strat in self.column_strategies.items():
            if col not in X_result.columns:
                continue
            
            if strat == 'ffill':
                X_result[col] = X_result[col].ffill()
            elif strat == 'bfill':
                X_result[col] = X_result[col].bfill()
            elif strat == 'zero':
                X_result[col] = X_result[col].fillna(0)
        
        return X_result
    
    def get_missing_report(self, X: pd.DataFrame) -> pd.DataFrame:
        """
        Táº¡o bÃ¡o cÃ¡o missing values.
        
        Args:
            X: DataFrame cáº§n kiá»ƒm tra
        
        Returns:
            DataFrame bÃ¡o cÃ¡o missing values
        """
        missing_count = X.isnull().sum()
        missing_percent = (X.isnull().sum() / len(X)) * 100
        
        report = pd.DataFrame({
            'column': X.columns,
            'missing_count': missing_count.values,
            'missing_percent': missing_percent.values,
            'dtype': X.dtypes.values
        })
        
        return report[report['missing_count'] > 0].sort_values('missing_count', ascending=False)
    
    def get_params(self, deep: bool = True) -> Dict[str, Any]:
        """Láº¥y parameters."""
        params = super().get_params(deep)
        params.update({
            'strategy': self.strategy,
            'fill_value': self.fill_value,
            'column_strategies': self.column_strategies,
            'n_neighbors': self.n_neighbors
        })
        return params


# ============================= OUTLIER HANDLER =============================

class OutlierHandler(BaseWeatherTransformer):
    """
    Handler xá»­ lÃ½ outliers.
    
    Há»— trá»£:
    - IQR method: Clip/remove values ngoÃ i Q1-1.5*IQR vÃ  Q3+1.5*IQR
    - Z-score method: Clip/remove values cÃ³ |z| > threshold
    - Percentile method: Clip giÃ¡ trá»‹ ngoÃ i percentile range
    
    Attributes:
        method: PhÆ°Æ¡ng phÃ¡p detect outliers ('iqr', 'zscore', 'percentile')
        action: HÃ nh Ä‘á»™ng vá»›i outliers ('clip', 'remove', 'nan')
        columns: Danh sÃ¡ch columns cáº§n xá»­ lÃ½
    """
    
    def __init__(
        self,
        method: str = 'iqr',
        action: str = 'clip',
        columns: Optional[List[str]] = None,
        iqr_multiplier: float = 1.5,
        zscore_threshold: float = 3.0,
        percentile_range: Tuple[float, float] = (1, 99)
    ):
        """
        Khá»Ÿi táº¡o OutlierHandler.
        
        Args:
            method: PhÆ°Æ¡ng phÃ¡p detect ('iqr', 'zscore', 'percentile')
            action: HÃ nh Ä‘á»™ng ('clip', 'remove', 'nan')
            columns: Danh sÃ¡ch columns (None = auto detect)
            iqr_multiplier: Multiplier cho IQR method
            zscore_threshold: Threshold cho z-score method
            percentile_range: Range cho percentile method (lower, upper)
        """
        super().__init__(name="OutlierHandler")
        
        self.method = method
        self.action = action
        self.columns = columns
        self.iqr_multiplier = iqr_multiplier
        self.zscore_threshold = zscore_threshold
        self.percentile_range = percentile_range
        
        self._bounds: Dict[str, Tuple[float, float]] = {}
        self._handle_columns: List[str] = []
    
    def fit(self, X: pd.DataFrame, y: Optional[pd.Series] = None) -> 'OutlierHandler':
        """
        Fit - tÃ­nh toÃ¡n bounds cho má»—i column.
        
        Args:
            X: DataFrame training data
            y: Target (khÃ´ng sá»­ dá»¥ng)
        
        Returns:
            self
        """
        # XÃ¡c Ä‘á»‹nh columns
        if self.columns is not None:
            self._handle_columns = [c for c in self.columns if c in X.columns]
        else:
            self._handle_columns = X.select_dtypes(include=[np.number]).columns.tolist()
        
        # TÃ­nh bounds cho má»—i column
        for col in self._handle_columns:
            if self.method == 'iqr':
                Q1 = X[col].quantile(0.25)
                Q3 = X[col].quantile(0.75)
                IQR = Q3 - Q1
                
                # Edge case: IQR=0 (e.g. zero-inflated data â‰¥75% same value)
                # â†’ clipping to [Q1, Q3] would destroy ALL variation.
                # Fallback: use min/max (no clipping) for this column.
                if IQR == 0:
                    lower = X[col].min()
                    upper = X[col].max()
                else:
                    lower = Q1 - self.iqr_multiplier * IQR
                    upper = Q3 + self.iqr_multiplier * IQR
                
            elif self.method == 'zscore':
                mean = X[col].mean()
                std = X[col].std()
                lower = mean - self.zscore_threshold * std
                upper = mean + self.zscore_threshold * std
                
            elif self.method == 'percentile':
                lower = X[col].quantile(self.percentile_range[0] / 100)
                upper = X[col].quantile(self.percentile_range[1] / 100)
            
            else:
                lower, upper = X[col].min(), X[col].max()
            
            self._bounds[col] = (lower, upper)
        
        self.is_fitted = True
        self._fitted_columns = X.columns.tolist()
        
        logger.info(f"âœ… OutlierHandler ({self.method}) Ä‘Ã£ fit {len(self._handle_columns)} columns")
        return self
    
    def transform(self, X: pd.DataFrame) -> pd.DataFrame:
        """
        Transform - xá»­ lÃ½ outliers.
        
        Args:
            X: DataFrame cáº§n transform
        
        Returns:
            DataFrame Ä‘Ã£ xá»­ lÃ½ outliers
        """
        if not self.is_fitted:
            raise ValueError("OutlierHandler chÆ°a Ä‘Æ°á»£c fit! Gá»i fit() trÆ°á»›c.")
        
        X_result = X.copy()
        
        for col in self._handle_columns:
            if col not in X_result.columns:
                continue
            
            lower, upper = self._bounds.get(col, (X_result[col].min(), X_result[col].max()))
            
            if self.action == 'clip':
                X_result[col] = X_result[col].clip(lower=lower, upper=upper)
            
            elif self.action == 'nan':
                mask = (X_result[col] < lower) | (X_result[col] > upper)
                X_result.loc[mask, col] = np.nan
            
            # 'remove' sáº½ Ä‘Æ°á»£c handle á»Ÿ level pipeline
        
        return X_result
    
    def get_params(self, deep: bool = True) -> Dict[str, Any]:
        """Láº¥y parameters."""
        params = super().get_params(deep)
        params.update({
            'method': self.method,
            'action': self.action,
            'columns': self.columns,
            'iqr_multiplier': self.iqr_multiplier,
            'zscore_threshold': self.zscore_threshold,
            'percentile_range': self.percentile_range
        })
        return params


# ============================= WEATHER TRANSFORM PIPELINE =============================

class WeatherTransformPipeline:
    """
    Pipeline transform thá»‘ng nháº¥t cho train & predict.
    
    ÄÃ¢y lÃ  class chÃ­nh Ä‘á»ƒ Ä‘áº£m báº£o:
    - Train vÃ  predict dÃ¹ng Ä‘Ãºng cÃ¹ng 1 kiá»ƒu transform
    - CÃ³ thá»ƒ save/load pipeline
    - Tá»± Ä‘á»™ng xá»­ lÃ½ theo Ä‘Ãºng thá»© tá»±
    
    Pipeline steps:
        1. Missing value handling
        2. Outlier handling (optional)
        3. Categorical encoding
        4. Numerical scaling
    
    Attributes:
        steps: List cÃ¡c transformer steps
        is_fitted: Tráº¡ng thÃ¡i Ä‘Ã£ fit chÆ°a
    """
    
    def __init__(
        self,
        missing_strategy: str = 'median',
        scaler_type: str = 'standard',
        encoding_type: str = 'label',
        handle_outliers: bool = False,
        outlier_method: str = 'iqr',
        custom_steps: Optional[List[BaseWeatherTransformer]] = None
    ):
        """
        Khá»Ÿi táº¡o WeatherTransformPipeline.
        
        Args:
            missing_strategy: Chiáº¿n lÆ°á»£c xá»­ lÃ½ missing values
            scaler_type: Loáº¡i scaler
            encoding_type: Loáº¡i encoding cho categorical
            handle_outliers: CÃ³ xá»­ lÃ½ outliers khÃ´ng
            outlier_method: PhÆ°Æ¡ng phÃ¡p xá»­ lÃ½ outliers
            custom_steps: List cÃ¡c custom transformer steps
        """
        self.missing_strategy = missing_strategy
        self.scaler_type = scaler_type
        self.encoding_type = encoding_type
        self.handle_outliers = handle_outliers
        self.outlier_method = outlier_method
        
        # Initialize steps
        if custom_steps is not None:
            self.steps = custom_steps
        else:
            self.steps = self._create_default_steps()
        
        self.is_fitted = False
        self._feature_names: List[str] = []
        self._fitted_at: Optional[str] = None
    
    def _create_default_steps(self) -> List[BaseWeatherTransformer]:
        """Táº¡o default pipeline steps."""
        steps = []
        
        # Step 1: Missing value handler
        steps.append(MissingValueHandler(strategy=self.missing_strategy))
        
        # Step 2: Outlier handler (optional)
        if self.handle_outliers:
            steps.append(OutlierHandler(method=self.outlier_method, action='clip'))
        
        # Step 3: Categorical encoder
        steps.append(CategoricalEncoder(encoding_type=self.encoding_type))
        
        # Step 4: Scaler
        steps.append(WeatherScaler(scaler_type=self.scaler_type))
        
        return steps
    
    def fit(self, X: pd.DataFrame, y: Optional[pd.Series] = None) -> 'WeatherTransformPipeline':
        """
        Fit táº¥t cáº£ steps trong pipeline.
        
        Args:
            X: DataFrame training data
            y: Target (truyá»n cho target encoding náº¿u cáº§n)
        
        Returns:
            self
        """
        logger.info("ğŸš€ Báº¯t Ä‘áº§u fit WeatherTransformPipeline...")
        
        X_current = X.copy()
        
        for i, step in enumerate(self.steps):
            logger.info(f"   Step {i+1}/{len(self.steps)}: {step.name}")
            X_current = step.fit_transform(X_current, y)
        
        self._feature_names = X_current.columns.tolist()
        self.is_fitted = True
        self._fitted_at = datetime.now().isoformat()
        
        logger.info(f"âœ… WeatherTransformPipeline Ä‘Ã£ fit thÃ nh cÃ´ng!")
        logger.info(f"   - Input shape: {X.shape}")
        logger.info(f"   - Output shape: {X_current.shape}")
        
        return self
    
    def transform(self, X: pd.DataFrame) -> pd.DataFrame:
        """
        Transform dá»¯ liá»‡u vá»›i pipeline Ä‘Ã£ fit.
        
        Args:
            X: DataFrame cáº§n transform
        
        Returns:
            DataFrame Ä‘Ã£ Ä‘Æ°á»£c transform
        """
        if not self.is_fitted:
            raise ValueError("WeatherTransformPipeline chÆ°a Ä‘Æ°á»£c fit! Gá»i fit() trÆ°á»›c.")
        
        X_current = X.copy()
        
        for step in self.steps:
            X_current = step.transform(X_current)
        
        return X_current
    
    def fit_transform(self, X: pd.DataFrame, y: Optional[pd.Series] = None) -> pd.DataFrame:
        """
        Fit vÃ  transform trong má»™t bÆ°á»›c.
        
        Args:
            X: DataFrame training data
            y: Target
        
        Returns:
            DataFrame Ä‘Ã£ Ä‘Æ°á»£c transform
        """
        self.fit(X, y)
        return self.transform(X)
    
    def inverse_transform(self, X: pd.DataFrame) -> pd.DataFrame:
        """
        Inverse transform (chá»‰ cho scaler).
        
        Args:
            X: DataFrame Ä‘Ã£ transform
        
        Returns:
            DataFrame vá»›i giÃ¡ trá»‹ gá»‘c (chá»‰ numerical columns)
        """
        X_current = X.copy()
        
        # Inverse transform theo thá»© tá»± ngÆ°á»£c
        for step in reversed(self.steps):
            if hasattr(step, 'inverse_transform'):
                X_current = step.inverse_transform(X_current)
        
        return X_current
    
    def get_feature_names(self) -> List[str]:
        """Láº¥y danh sÃ¡ch feature names sau transform."""
        return self._feature_names
    
    def save(self, path: Union[str, Path]) -> None:
        """
        LÆ°u pipeline ra file.
        
        Args:
            path: ÄÆ°á»ng dáº«n file (.pkl)
        """
        if not self.is_fitted:
            raise ValueError("Pipeline chÆ°a Ä‘Æ°á»£c fit! KhÃ´ng thá»ƒ save.")
        
        save_data = {
            'steps': self.steps,
            'is_fitted': self.is_fitted,
            'feature_names': self._feature_names,
            'fitted_at': self._fitted_at,
            'config': {
                'missing_strategy': self.missing_strategy,
                'scaler_type': self.scaler_type,
                'encoding_type': self.encoding_type,
                'handle_outliers': self.handle_outliers,
                'outlier_method': self.outlier_method
            }
        }
        
        path = Path(path)
        path.parent.mkdir(parents=True, exist_ok=True)
        
        joblib.dump(save_data, path)
        logger.info(f"âœ… Pipeline Ä‘Ã£ Ä‘Æ°á»£c lÆ°u táº¡i: {path}")
    
    @classmethod
    def load(cls, path: Union[str, Path]) -> 'WeatherTransformPipeline':
        """
        Load pipeline tá»« file.
        
        Args:
            path: ÄÆ°á»ng dáº«n file (.pkl)
        
        Returns:
            WeatherTransformPipeline instance
        """
        path = Path(path)
        
        if not path.exists():
            raise FileNotFoundError(f"KhÃ´ng tÃ¬m tháº¥y file pipeline: {path}")
        
        save_data = joblib.load(path)
        
        # Táº¡o instance má»›i
        config = save_data.get('config', {})
        pipeline = cls(
            missing_strategy=config.get('missing_strategy', 'median'),
            scaler_type=config.get('scaler_type', 'standard'),
            encoding_type=config.get('encoding_type', 'label'),
            handle_outliers=config.get('handle_outliers', False),
            outlier_method=config.get('outlier_method', 'iqr')
        )
        
        # Restore state
        pipeline.steps = save_data['steps']
        pipeline.is_fitted = save_data['is_fitted']
        pipeline._feature_names = save_data['feature_names']
        pipeline._fitted_at = save_data.get('fitted_at')
        
        logger.info(f"âœ… Pipeline Ä‘Ã£ Ä‘Æ°á»£c load tá»«: {path}")
        return pipeline
    
    def get_pipeline_info(self) -> Dict[str, Any]:
        """Láº¥y thÃ´ng tin vá» pipeline."""
        return {
            'is_fitted': self.is_fitted,
            'fitted_at': self._fitted_at,
            'n_steps': len(self.steps),
            'steps': [step.name for step in self.steps],
            'n_features': len(self._feature_names),
            'config': {
                'missing_strategy': self.missing_strategy,
                'scaler_type': self.scaler_type,
                'encoding_type': self.encoding_type,
                'handle_outliers': self.handle_outliers
            }
        }


# ============================= UTILITY FUNCTIONS =============================

def create_default_pipeline() -> WeatherTransformPipeline:
    """
    Táº¡o pipeline máº·c Ä‘á»‹nh cho weather data.
    
    Returns:
        WeatherTransformPipeline instance
    """
    return WeatherTransformPipeline(
        missing_strategy='median',
        scaler_type='standard',
        encoding_type='label',
        handle_outliers=True,
        outlier_method='iqr'
    )


def create_minimal_pipeline() -> WeatherTransformPipeline:
    """
    Táº¡o pipeline tá»‘i giáº£n (chá»‰ xá»­ lÃ½ missing vÃ  scale).
    
    Returns:
        WeatherTransformPipeline instance
    """
    return WeatherTransformPipeline(
        missing_strategy='median',
        scaler_type='standard',
        encoding_type='label',
        handle_outliers=False
    )


def get_scaler(scaler_type: str = 'standard', **kwargs) -> WeatherScaler:
    """
    Factory function Ä‘á»ƒ táº¡o scaler.
    
    Args:
        scaler_type: Loáº¡i scaler
        **kwargs: Additional kwargs
    
    Returns:
        WeatherScaler instance
    """
    return WeatherScaler(scaler_type=scaler_type, **kwargs)


def get_encoder(encoding_type: str = 'label', **kwargs) -> CategoricalEncoder:
    """
    Factory function Ä‘á»ƒ táº¡o encoder.
    
    Args:
        encoding_type: Loáº¡i encoding
        **kwargs: Additional kwargs
    
    Returns:
        CategoricalEncoder instance
    """
    return CategoricalEncoder(encoding_type=encoding_type, **kwargs)


# ============================= MODULE TEST =============================

if __name__ == "__main__":
    print("=" * 60)
    print("ğŸ§ª Testing Transformers Module")
    print("=" * 60)
    
    # Táº¡o sample data
    np.random.seed(42)
    n_samples = 100
    
    sample_data = pd.DataFrame({
        'nhiet_do': np.random.uniform(20, 35, n_samples),
        'do_am': np.random.uniform(60, 95, n_samples),
        'ap_suat': np.random.uniform(1005, 1020, n_samples),
        'toc_do_gio': np.random.uniform(0, 15, n_samples),
        'luong_mua': np.random.exponential(2, n_samples),
        'region': np.random.choice(['north', 'central', 'south'], n_samples),
        'station': np.random.choice(['A', 'B', 'C'], n_samples)
    })
    
    # ThÃªm missing values
    sample_data.loc[np.random.choice(n_samples, 10, replace=False), 'nhiet_do'] = np.nan
    sample_data.loc[np.random.choice(n_samples, 5, replace=False), 'do_am'] = np.nan
    
    # ThÃªm outliers
    sample_data.loc[0, 'nhiet_do'] = 100  # Outlier
    sample_data.loc[1, 'luong_mua'] = 500  # Outlier
    
    print(f"ğŸ“Š Sample data shape: {sample_data.shape}")
    print(f"ğŸ“Š Missing values:\n{sample_data.isnull().sum()}")
    
    # Test pipeline
    print("\nğŸ”„ Testing WeatherTransformPipeline...")
    pipeline = WeatherTransformPipeline(
        missing_strategy='median',
        scaler_type='standard',
        encoding_type='label',
        handle_outliers=True
    )
    
    X_transformed = pipeline.fit_transform(sample_data)
    
    print(f"\nğŸ“Š Transformed shape: {X_transformed.shape}")
    print(f"ğŸ“Š Missing after transform: {X_transformed.isnull().sum().sum()}")
    print(f"\nğŸ“‹ Pipeline info:")
    for key, value in pipeline.get_pipeline_info().items():
        print(f"   {key}: {value}")
    
    # Test save/load
    print("\nğŸ’¾ Testing save/load...")
    pipeline.save('test_pipeline.pkl')
    loaded_pipeline = WeatherTransformPipeline.load('test_pipeline.pkl')
    print(f"âœ… Pipeline loaded successfully")
    
    # Clean up
    import os
    os.remove('test_pipeline.pkl')
    
    print("\n" + "=" * 60)
    print("ğŸ Test hoÃ n thÃ nh")
    print("=" * 60)